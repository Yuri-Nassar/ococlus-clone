{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import omega_index_py3 as oi\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import os, sys, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each algorithm has its block to facilitate the manipulation of it if the reader wants. Thus, feel free to change it to fit your needs. We ran the CORALS algorithm (it is based on MatLab) apart and computed the scores in this file. You can compute the reconstruction error from his code just by making simple adaptations on his project. Please, check Li's paper to get access to his project code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for traditional clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to compute the reconstruction error\n",
    "syn1 = './data/synthetic/preprocessed/Toy1_b4_binary_fortraditional.dat'\n",
    "syn2 = './data/synthetic/preprocessed/Toy2_b5_binary_fortraditional.dat'\n",
    "syn3 = './data/synthetic/preprocessed/Toy3_b2_binary_fortraditional.dat'\n",
    "files_reconstruct = [syn1, syn2, syn3]\n",
    "\n",
    "file1 = './data/synthetic/preprocessed/Toy1_b4_binary_fortraditional.dat'#synthetic-1\n",
    "file2 = './data/synthetic/preprocessed/Toy2_b5_binary_fortraditional.dat'#synthetic-2\n",
    "file3 = './data/synthetic/preprocessed/Toy3_b2_binary_fortraditional.dat'#synthetic-3\n",
    "datasets = [file1, file2, file3]\n",
    "clusters = [6,7,3] # number of clusters that traditinal clustering found in the ground-truth, respectively.\n",
    "numberOfRuns = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurin\\Documents\\my_github\\ococlus\n",
      "kmeans' folder was cleaned.\n",
      "\n",
      "Dataset: Syn-1\n",
      "Run-1\n",
      "Reconstruction error:  6762\n",
      "\n",
      "Dataset: Syn-2\n",
      "Run-1\n",
      "Reconstruction error:  368875\n",
      "\n",
      "Dataset: Syn-3\n",
      "Run-1\n",
      "Reconstruction error:  3800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "path_method = \"OutputAnalysis\\kmeans\"\n",
    "check_path(path_method)\n",
    "\n",
    "for ds in range(len(datasets)):\n",
    "    ds_name = \"Syn-\"+str(ds+1)\n",
    "    print(\"\\nDataset: \"+ds_name)\n",
    "    res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "\n",
    "    for run in range(numberOfRuns):\n",
    "        print(\"Run-\"+str(run+1))\n",
    "        df = pd.read_csv(datasets[ds],header=None)\n",
    "        df.columns = [str(i) for i in range(df.shape[1])]\n",
    "        ncols = df.shape[1]\n",
    "        data = df.values.copy()\n",
    "        del df\n",
    "\n",
    "#         kmeans = KMeans(n_clusters = clusters[ds], random_state = 0)\n",
    "        kmeans = KMeans(n_clusters = clusters[ds])\n",
    "        kmeans.fit(data)\n",
    "        ids_clus = list(set(kmeans.labels_))\n",
    "        reconstructed_matrix = np.ones(data.shape,dtype=int)\n",
    "#         print(\"Data cost: \",data.sum())\n",
    "        print(\"Reconstruction error: \",np.sum(np.bitwise_xor(data,reconstructed_matrix)))\n",
    "        del data, reconstructed_matrix\n",
    "        gc.collect()\n",
    "        \n",
    "        clustering = build_clustering_output_omega(ids_clus,(kmeans.labels_,ncols),trad=True)\n",
    "\n",
    "        # XMEASURES format ground-truth C++ version\n",
    "        kmeans_clustering_xm = xmeasures_format(clustering)\n",
    "        df_gt = pd.DataFrame(kmeans_clustering_xm)\n",
    "#         name = datasets[ds].split(\"/\")[-1]\n",
    "#         name = name.split(\".\")[0]\n",
    "        path = path_method+\"/\"+ds_name\n",
    "        df_gt.to_csv(path.replace(\"\\\\\",\"/\")+\"/run_\"+str(run+1)+\"_res_kmeans_\"+ds_name+\"_trad.cnl\", \n",
    "                     header= False,index=False, encoding='utf8')\n",
    "        del clustering, df_gt, kmeans_clustering_xm\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists. Clean it.\n",
      " \n",
      "File OutputAnalysis/kmeans/Syn-3/run_1_res_kmeans_Syn-3_trad.cnl is not empty. It has 3 lines.\n",
      " \n",
      " \n",
      "= Overlaps Evaluation =\n",
      "MF1p_u (PARTPROB, UNWEIGHTED):\n",
      "0.44036 (Prc: 0.41129, Rec: 0.473852)\n",
      "OI:\n",
      "0.0623153\n",
      "MF1p_u: 0.44036 (Prc: 0.41129, Rec: 0.473852); OI: 0.0623153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the nodes in the collections differ (the quality will be penalized): 3200 nodes with hash 16332818011922301848, size: 3200, ids: 3695102400, id2s: 7185057752512) != 7000 nodes with hash 13278174547081972885, size: 7000, ids: 8209015500, id2s: 15763208793764);  synchronize: no, label: no\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "### omega index and f-score from Xmeasures project\n",
    "### ./xmeasures -o -fp -ku -O gt.txt cls2.txt\n",
    "# pwd\n",
    "# ls\n",
    "\n",
    "if [ -d \"xmeasures/OutputAnalysis/kmeans\" ] \n",
    "then\n",
    "    echo \"Directory exists. Clean it.\"\n",
    "    rm -R xmeasures/OutputAnalysis/kmeans\n",
    "else\n",
    "    echo \"Directory does not exists. Create it now.\"\n",
    "fi\n",
    "\n",
    "cp -R OutputAnalysis xmeasures\n",
    "cd xmeasures/\n",
    "\n",
    "#Methods: [Kmeans]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl, gt_xm_s2_trad.cnl, gt_xm_s3_trad.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/kmeans/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./xmeasures -o -fp -ku -O ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "File OutputAnalysis/kmeans/Syn-3/run_1_res_kmeans_Syn-3_trad.cnl is not empty. It has 3 lines.\n",
      " \n",
      " \n",
      "# Average estimated membership in './gts/gt_xm_s3_trad.cnl': 0.6696 (6200 / 9259)\n",
      "# Average estimated membership in 'OutputAnalysis/kmeans/Syn-3/run_1_res_kmeans_Syn-3_trad.cnl': 0.6812 (7000 / 10276)\n",
      "0.153246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the number of nodes is different in the collections (the quality will be penalized): 3200 != 7000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "#### ONMI from Xmeasures project\n",
    "#### ./onmi file1 file2\n",
    "\n",
    "cd xmeasures\n",
    "\n",
    "#Method: [kmeans]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl,gt_xm_s2_trad.cnl,gt_xm_s3_trad.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/kmeans/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./onmi ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurin\\Documents\\my_github\\ococlus\n",
      "The path was created: OutputAnalysis\\dbscan\n",
      "\n",
      "Dataset: Syn-1\n",
      "Run-1\n",
      "Reconstruction error:  6762\n",
      "\n",
      "Dataset: Syn-2\n",
      "Run-1\n",
      "Reconstruction error:  368875\n",
      "\n",
      "Dataset: Syn-3\n",
      "Run-1\n",
      "Reconstruction error:  3800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "path_method = \"OutputAnalysis\\dbscan\"\n",
    "check_path(path_method)\n",
    "for ds in range(len(datasets)):\n",
    "    ds_name = \"Syn-\"+str(ds+1)\n",
    "    print(\"\\nDataset: \"+ds_name)\n",
    "    res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "\n",
    "    for run in range(numberOfRuns):\n",
    "        print(\"Run-\"+str(run+1))\n",
    "    \n",
    "        df = pd.read_csv(datasets[ds],header=None)\n",
    "        df.columns = [str(i) for i in range(df.shape[1])]\n",
    "        ncols = df.shape[1]\n",
    "        data = df.values.copy()\n",
    "        del df\n",
    "\n",
    "        dbscan = DBSCAN(eps = 0.5, min_samples = 5) # default parameters\n",
    "        dbscan.fit(data)\n",
    "\n",
    "        ids_clus = [ele for ele in list(set(dbscan.labels_)) if ele != -1 ]\n",
    "\n",
    "        reconstructed_matrix = np.zeros(data.shape,dtype=int)\n",
    "        for i in range(len(dbscan.labels_)):\n",
    "            if dbscan.labels_[i] != -1: #mark the elements if it's not noise\n",
    "                reconstructed_matrix[i,:] = 1\n",
    "#         print(\"Data cost: \",data.sum())\n",
    "        print(\"Reconstruction error: \",np.sum(np.bitwise_xor(data,reconstructed_matrix)))\n",
    "        del data, reconstructed_matrix\n",
    "        gc.collect()\n",
    "        \n",
    "        clustering = build_clustering_output_omega(ids_clus,(dbscan.labels_,ncols),trad=True)\n",
    "\n",
    "        # XMEASURES format ground-truth C++ version\n",
    "        dbscan_clustering_xm = xmeasures_format(clustering)\n",
    "        df_gt = pd.DataFrame(dbscan_clustering_xm)\n",
    "        path = path_method+\"/\"+ds_name\n",
    "        df_gt.to_csv(path.replace(\"\\\\\",\"/\")+\"/run_\"+str(run+1)+\"_res_dbscan_\"+ds_name+\"_trad.cnl\", \n",
    "                     header= False,index=False, encoding='utf8')\n",
    "        del clustering, df_gt, dbscan_clustering_xm\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exists. Create it now.\n",
      " \n",
      "File OutputAnalysis/dbscan/Syn-3/run_1_res_dbscan_Syn-3_trad.cnl is not empty. It has 3 lines.\n",
      " \n",
      " \n",
      "= Overlaps Evaluation =\n",
      "MF1p_u (PARTPROB, UNWEIGHTED):\n",
      "0.44036 (Prc: 0.41129, Rec: 0.473852)\n",
      "OI:\n",
      "0.0623153\n",
      "MF1p_u: 0.44036 (Prc: 0.41129, Rec: 0.473852); OI: 0.0623153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the nodes in the collections differ (the quality will be penalized): 3200 nodes with hash 16332818011922301848, size: 3200, ids: 3695102400, id2s: 7185057752512) != 7000 nodes with hash 13278174547081972885, size: 7000, ids: 8209015500, id2s: 15763208793764);  synchronize: no, label: no\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "### omega index and f-score from Xmeasures project\n",
    "### ./xmeasures -o -fp -ku -O gt.txt cls2.txt\n",
    "# pwd\n",
    "# ls\n",
    "\n",
    "if [ -d \"xmeasures/OutputAnalysis/dbscan\" ] \n",
    "then\n",
    "    echo \"Directory exists. Clean it.\"\n",
    "    rm -R xmeasures/OutputAnalysis/dbscan\n",
    "else\n",
    "    echo \"Directory does not exists. Create it now.\"\n",
    "fi\n",
    "\n",
    "cp -R OutputAnalysis xmeasures\n",
    "cd xmeasures/\n",
    "\n",
    "#Methods: [Kmeans]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl, gt_xm_s2_trad.cnl, gt_xm_s3_trad.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/dbscan/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./xmeasures -o -fp -ku -O ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "File OutputAnalysis/dbscan/Syn-3/run_1_res_dbscan_Syn-3_trad.cnl is not empty. It has 3 lines.\n",
      " \n",
      " \n",
      "# Average estimated membership in './gts/gt_xm_s3_trad.cnl': 0.6696 (6200 / 9259)\n",
      "# Average estimated membership in 'OutputAnalysis/dbscan/Syn-3/run_1_res_dbscan_Syn-3_trad.cnl': 0.6812 (7000 / 10276)\n",
      "0.153246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the number of nodes is different in the collections (the quality will be penalized): 3200 != 7000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "#### ONMI from Xmeasures project\n",
    "#### ./onmi file1 file2\n",
    "\n",
    "cd xmeasures\n",
    "\n",
    "#Method: [kmeans]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl,gt_xm_s2_trad.cnl,gt_xm_s3_trad.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/dbscan/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./onmi ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierachical clustering (Agglomerative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurin\\Documents\\my_github\\ococlus\n",
      "The path was created: OutputAnalysis\\Agglomerative\n",
      "\n",
      "Dataset: Syn-1\n",
      "Run-1\n",
      "Reconstruction error:  6762\n",
      "\n",
      "Dataset: Syn-2\n",
      "Run-1\n",
      "Reconstruction error:  368875\n",
      "\n",
      "Dataset: Syn-3\n",
      "Run-1\n",
      "Reconstruction error:  3800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "path_method = \"OutputAnalysis\\Agglomerative\"\n",
    "check_path(path_method)\n",
    "for ds in range(len(datasets)):\n",
    "    ds_name = \"Syn-\"+str(ds+1)\n",
    "    print(\"\\nDataset: \"+ds_name)\n",
    "    res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "\n",
    "    for run in range(numberOfRuns):\n",
    "        print(\"Run-\"+str(run+1))\n",
    "        \n",
    "        df = pd.read_csv(datasets[ds],header=None)\n",
    "        df.columns = [str(i) for i in range(df.shape[1])]\n",
    "        ncols = df.shape[1]\n",
    "        data = df.values.copy()\n",
    "        del df\n",
    "\n",
    "        HClustering = AgglomerativeClustering(n_clusters=clusters[ds], linkage='ward') #default parameters\n",
    "        HClustering.fit(data)\n",
    "\n",
    "        reconstructed_matrix = np.ones(data.shape,dtype=int)\n",
    "        ids_clus = list(set(HClustering.labels_))\n",
    "#         print(\"Data cost: \",data.sum())\n",
    "        print(\"Reconstruction error: \",np.sum(np.bitwise_xor(data,reconstructed_matrix)))\n",
    "        del reconstructed_matrix, data\n",
    "        gc.collect()\n",
    "        \n",
    "        clustering = build_clustering_output_omega(ids_clus,(HClustering.labels_,ncols),trad=True)\n",
    "\n",
    "        # XMEASURES format ground-truth C++ version\n",
    "        HClustering_clustering_xm = xmeasures_format(clustering)\n",
    "        df_gt = pd.DataFrame(HClustering_clustering_xm)\n",
    "        path = path_method+\"/\"+ds_name\n",
    "        df_gt.to_csv(path.replace(\"\\\\\",\"/\")+\"/run_\"+str(run+1)+\"_res_agglomerative_\"+ds_name+\"_trad.cnl\", \n",
    "                     header= False,index=False, encoding='utf8')\n",
    "        del clustering, df_gt, HClustering_clustering_xm\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exists. Create it now.\n",
      " \n",
      "File OutputAnalysis/Agglomerative/Syn-3/run_1_res_agglomerative_Syn-3_trad.cnl is not empty. It has 3 lines.\n",
      " \n",
      " \n",
      "= Overlaps Evaluation =\n",
      "MF1p_u (PARTPROB, UNWEIGHTED):\n",
      "0.44036 (Prc: 0.41129, Rec: 0.473852)\n",
      "OI:\n",
      "0.0623153\n",
      "MF1p_u: 0.44036 (Prc: 0.41129, Rec: 0.473852); OI: 0.0623153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the nodes in the collections differ (the quality will be penalized): 3200 nodes with hash 16332818011922301848, size: 3200, ids: 3695102400, id2s: 7185057752512) != 7000 nodes with hash 13278174547081972885, size: 7000, ids: 8209015500, id2s: 15763208793764);  synchronize: no, label: no\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "### omega index and f-score from Xmeasures project\n",
    "### ./xmeasures -o -fp -ku -O gt.txt cls2.txt\n",
    "# pwd\n",
    "# ls\n",
    "\n",
    "if [ -d \"xmeasures/OutputAnalysis/Agglomerative\" ] \n",
    "then\n",
    "    echo \"Directory exists. Clean it.\"\n",
    "    rm -R xmeasures/OutputAnalysis/Agglomerative\n",
    "else\n",
    "    echo \"Directory does not exists. Create it now.\"\n",
    "fi\n",
    "\n",
    "cp -R OutputAnalysis xmeasures\n",
    "cd xmeasures/\n",
    "\n",
    "#Methods: [Kmeans]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl, gt_xm_s2_trad.cnl, gt_xm_s3_trad.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/Agglomerative/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./xmeasures -o -fp -ku -O ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "File OutputAnalysis/Agglomerative/Syn-3/run_1_res_agglomerative_Syn-3_trad.cnl is not empty. It has 3 lines.\n",
      " \n",
      " \n",
      "# Average estimated membership in './gts/gt_xm_s3_trad.cnl': 0.6696 (6200 / 9259)\n",
      "# Average estimated membership in 'OutputAnalysis/Agglomerative/Syn-3/run_1_res_agglomerative_Syn-3_trad.cnl': 0.6812 (7000 / 10276)\n",
      "0.153246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the number of nodes is different in the collections (the quality will be penalized): 3200 != 7000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "#### ONMI from Xmeasures project\n",
    "#### ./onmi file1 file2\n",
    "\n",
    "cd xmeasures\n",
    "\n",
    "#Method: [kmeans]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl,gt_xm_s2_trad.cnl,gt_xm_s3_trad.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/Agglomerative/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./onmi ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for co-clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn1 = './data/synthetic/preprocessed/Toy1_b4_binary_forcocluster.dat'\n",
    "syn2 = './data/synthetic/preprocessed/Toy2_b5_binary_forcocluster.dat'\n",
    "syn3 = './data/synthetic/preprocessed/Toy3_b2_binary_forcocluster.dat'\n",
    "files_reconstruct = [syn1, syn2, syn3]\n",
    "\n",
    "file1 = './data/synthetic/preprocessed/Toy1_b4_binary_forcocluster.dat'#synthetic-1\n",
    "file2 = './data/synthetic/preprocessed/Toy2_b5_binary_forcocluster.dat'#synthetic-2\n",
    "file3 = './data/synthetic/preprocessed/Toy3_b2_binary_forcocluster.dat'#synthetic-3\n",
    "datasets = [file1, file2, file3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-clustering (Block diagonal) - Dhillon (2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurin\\Documents\\my_github\\ococlus\n",
      "dhillon' folder was cleaned.\n",
      "\n",
      "Dataset: Syn-1\n",
      "Run-1\n",
      "Reconstruction error:  1404\n",
      "\n",
      "Dataset: Syn-2\n",
      "Run-1\n",
      "Reconstruction error:  31426\n",
      "\n",
      "Dataset: Syn-3\n",
      "Run-1\n",
      "Reconstruction error:  2200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "clusters = [7,10,4] # number of co-clusters in the ground-truth data, respectively.\n",
    "path_method = \"OutputAnalysis\\dhillon\"\n",
    "check_path(path_method)\n",
    "for ds in range(len(datasets)):\n",
    "    ds_name = \"Syn-\"+str(ds+1)\n",
    "    print(\"\\nDataset: \"+ds_name)\n",
    "    res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "\n",
    "    for run in range(numberOfRuns):\n",
    "        print(\"Run-\"+str(run+1))\n",
    "        \n",
    "        df = pd.read_csv(datasets[ds],header=None)\n",
    "        df.columns = [i+1 for i in range(df.shape[1])]\n",
    "        data = df.values.copy()\n",
    "        del df\n",
    "\n",
    "        DhillonCocluster = SpectralCoclustering(n_clusters = clusters[ds])\n",
    "        DhillonCocluster.fit(data)\n",
    "\n",
    "        # Reconstruct matrix\n",
    "        reconstructed_matrix = np.zeros(data.shape,dtype=int)\n",
    "        for nc in range(clusters[ds]):\n",
    "            if len(DhillonCocluster.get_indices(nc)[0]) != 0 and len(DhillonCocluster.get_indices(nc)[1]) != 0:\n",
    "                for i in DhillonCocluster.get_indices(nc)[0]:\n",
    "                    for j in DhillonCocluster.get_indices(nc)[1]:\n",
    "                        reconstructed_matrix[i][j] = 1\n",
    "#         print(\"Data cost: \",data.sum())\n",
    "        print(\"Reconstruction error: \",np.sum(np.bitwise_xor(data,reconstructed_matrix)))\n",
    "        \n",
    "        clustering = build_clustering_output_omega(clusters[ds],DhillonCocluster) #format to omega and f-score measure\n",
    "\n",
    "        # XMEASURES format ground-truth C++ version\n",
    "        DhillonCocluster_clustering_xm = xmeasures_format(clustering)\n",
    "        df_gt = pd.DataFrame(DhillonCocluster_clustering_xm)\n",
    "        path = path_method+\"/\"+ds_name\n",
    "        df_gt.to_csv(path.replace(\"\\\\\",\"/\")+\"/run_\"+str(run+1)+\"_res_dhillon_\"+ds_name+\"_co.cnl\", \n",
    "                     header= False,index=False, encoding='utf8')\n",
    "        del reconstructed_matrix, clustering, df_gt, DhillonCocluster_clustering_xm\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exists. Create it now.\n",
      " \n",
      "File OutputAnalysis/dhillon/Syn-3/run_1_res_dhillon_Syn-3_co.cnl is not empty. It has 2 lines.\n",
      " \n",
      " \n",
      "= Overlaps Evaluation =\n",
      "MF1p_u (PARTPROB, UNWEIGHTED):\n",
      "0.385612 (Prc: 0.325192, Rec: 0.473607)\n",
      "OI:\n",
      "-0.0122583\n",
      "MF1p_u: 0.385612 (Prc: 0.325192, Rec: 0.473607); OI: -0.0122583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the nodes in the collections differ (the quality will be penalized): 3200 nodes with hash 16332818011922301848, size: 3200, ids: 3695102400, id2s: 7185057752512) != 1000 nodes with hash 7130370568895277204, size: 1000, ids: 879620500, id2s: 2274756543100);  synchronize: no, label: no\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "### omega index and f-score from Xmeasures project\n",
    "### ./xmeasures -o -fp -ku -O gt.txt cls2.txt\n",
    "# pwd\n",
    "# ls\n",
    "\n",
    "if [ -d \"xmeasures/OutputAnalysis/dhillon\" ] \n",
    "then\n",
    "    echo \"Directory exists. Clean it.\"\n",
    "    rm -R xmeasures/OutputAnalysis/dhillon\n",
    "else\n",
    "    echo \"Directory does not exists. Create it now.\"\n",
    "fi\n",
    "\n",
    "cp -R OutputAnalysis xmeasures\n",
    "cd xmeasures/\n",
    "\n",
    "#Methods: [Dhillon]\n",
    "#ground-truth: [gt_xm_s1_co.cnl, gt_xm_s2_co.cnl, gt_xm_s3_co.cnl]\n",
    "# for i in 1 2 3 # checking all datasets\n",
    "for i in 3 # checking a specific dataset\n",
    "do\n",
    "    for file in OutputAnalysis/dhillon/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./xmeasures -o -fp -ku -O ./gts/gt_xm_s${i}_co.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "File OutputAnalysis/dhillon/Syn-3/run_1_res_dhillon_Syn-3_co.cnl is not empty. It has 2 lines.\n",
      " \n",
      " \n",
      "# Average estimated membership in './gts/gt_xm_s3_co.cnl': 0.6696 (6200 / 9259)\n",
      "# Average estimated membership in 'OutputAnalysis/dhillon/Syn-3/run_1_res_dhillon_Syn-3_co.cnl': 0.5711 (1000 / 1751)\n",
      "0.156452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the number of nodes is different in the collections (the quality will be penalized): 3200 != 1000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "#### ONMI from Xmeasures project\n",
    "#### ./onmi file1 file2\n",
    "\n",
    "cd xmeasures\n",
    "\n",
    "#Method: [Dhillon]\n",
    "#ground-truth: [gt_xm_s1_co.cnl,gt_xm_s2_co.cnl,gt_xm_s3_co.cnl]\n",
    "# for i in 1 2 3 # checking all datasets\n",
    "for i in 3 # checking a specific dataset\n",
    "do\n",
    "    for file in OutputAnalysis/dhillon/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./onmi ./gts/gt_xm_s${i}_co.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-clustering (Checkerboard) - Kluger (2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurin\\Documents\\my_github\\ococlus\n",
      "kluger' folder was cleaned.\n",
      "\n",
      "Dataset: Syn-1\n",
      "Run-1\n",
      "Reconstruction error:  3759\n",
      "\n",
      "Dataset: Syn-2\n",
      "Run-1\n",
      "Reconstruction error:  343825\n",
      "\n",
      "Dataset: Syn-3\n",
      "Run-1\n",
      "Reconstruction error:  1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "clusters = [(6,5),(7,8),(3,3)] # number of co-clusters in the ground-truth data, respectively.\n",
    "path_method = \"OutputAnalysis\\kluger\"\n",
    "check_path(path_method)\n",
    "for ds in range(len(datasets)):\n",
    "    ds_name = \"Syn-\"+str(ds+1)\n",
    "    print(\"\\nDataset: \"+ds_name)\n",
    "    res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "\n",
    "    for run in range(numberOfRuns):\n",
    "        print(\"Run-\"+str(run+1))\n",
    "        \n",
    "        df = pd.read_csv(datasets[ds],header=None)\n",
    "        df.columns = [i+1 for i in range(df.shape[1])]\n",
    "        data = df.values.copy()\n",
    "        del df\n",
    "\n",
    "        KlugerCocluster = SpectralBiclustering(n_clusters = clusters[ds])\n",
    "        KlugerCocluster.fit(data)\n",
    "\n",
    "        reconstructed_kluger = np.zeros(data.shape,dtype=int)\n",
    "        for nc in range((clusters[ds][0]*clusters[ds][1])):\n",
    "            if len(KlugerCocluster.get_indices(nc)[0]) != 0 and len(KlugerCocluster.get_indices(nc)[1]) != 0:\n",
    "                for i in KlugerCocluster.get_indices(nc)[0]:\n",
    "                    for j in KlugerCocluster.get_indices(nc)[1]:\n",
    "                        reconstructed_kluger[i][j] = 1\n",
    "        print(\"Reconstruction error: \",np.sum(np.bitwise_xor(data,reconstructed_kluger)))\n",
    "        del reconstructed_kluger, data\n",
    "        gc.collect()\n",
    "        \n",
    "        clustering = build_clustering_output_omega(clusters[ds],KlugerCocluster) #format to omega and f-score measure\n",
    "\n",
    "        # XMEASURES format ground-truth C++ version\n",
    "        KlugerCocluster_clustering_xm = xmeasures_format(clustering)\n",
    "        df_gt = pd.DataFrame(KlugerCocluster_clustering_xm)\n",
    "        path = path_method+\"/\"+ds_name\n",
    "        df_gt.to_csv(path.replace(\"\\\\\",\"/\")+\"/run_\"+str(run+1)+\"_res_kluger_\"+ds_name+\"_co.cnl\", \n",
    "                     header= False,index=False, encoding='utf8')\n",
    "        del clustering, df_gt, KlugerCocluster_clustering_xm\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exists. Create it now.\n",
      " \n",
      "File OutputAnalysis/kluger/Syn-3/run_1_res_kluger_Syn-3_co.cnl is not empty. It has 9 lines.\n",
      " \n",
      " \n",
      "= Overlaps Evaluation =\n",
      "MF1p_u (PARTPROB, UNWEIGHTED):\n",
      "0.457622 (Prc: 0.580247, Rec: 0.377784)\n",
      "OI:\n",
      "0.0834991\n",
      "MF1p_u: 0.457622 (Prc: 0.580247, Rec: 0.377784); OI: 0.0834991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the nodes in the collections differ (the quality will be penalized): 3200 nodes with hash 16332818011922301848, size: 3200, ids: 3695102400, id2s: 7185057752512) != 4200 nodes with hash 14672793821654551294, size: 4200, ids: 4618734900, id2s: 9532372343452);  synchronize: no, label: no\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "### omega index and f-score from Xmeasures project\n",
    "### ./xmeasures -o -fp -ku -O gt.txt cls2.txt\n",
    "# pwd\n",
    "# ls\n",
    "\n",
    "if [ -d \"xmeasures/OutputAnalysis/kluger\" ] \n",
    "then\n",
    "    echo \"Directory exists. Clean it.\"\n",
    "    rm -R xmeasures/OutputAnalysis/kluger\n",
    "else\n",
    "    echo \"Directory does not exists. Create it now.\"\n",
    "fi\n",
    "\n",
    "cp -R OutputAnalysis xmeasures\n",
    "cd xmeasures/\n",
    "\n",
    "#Methods: [Kluger]\n",
    "#ground-truth: [gt_xm_s1_co.cnl, gt_xm_s2_co.cnl, gt_xm_s3_co.cnl]\n",
    "# for i in 1 2 3 # checking all datasets\n",
    "for i in 3 # checking a specific dataset\n",
    "do\n",
    "    for file in OutputAnalysis/kluger/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./xmeasures -o -fp -ku -O ./gts/gt_xm_s${i}_co.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "File OutputAnalysis/kluger/Syn-3/run_1_res_kluger_Syn-3_co.cnl is not empty. It has 9 lines.\n",
      " \n",
      " \n",
      "# Average estimated membership in './gts/gt_xm_s3_co.cnl': 0.6696 (6200 / 9259)\n",
      "# Average estimated membership in 'OutputAnalysis/kluger/Syn-3/run_1_res_kluger_Syn-3_co.cnl': 0.6636 (4200 / 6329)\n",
      "0.293504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING, the number of nodes is different in the collections (the quality will be penalized): 3200 != 4200\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "#### ONMI from Xmeasures project\n",
    "#### ./onmi file1 file2\n",
    "\n",
    "cd xmeasures\n",
    "\n",
    "#Method: [kluger]\n",
    "#ground-truth: [gt_xm_s1_co.cnl,gt_xm_s2_co.cnl,gt_xm_s3_co.cnl]\n",
    "# for i in 1 2 3\n",
    "for i in 3\n",
    "do\n",
    "    for file in OutputAnalysis/kluger/Syn-${i}/*\n",
    "    do\n",
    "        res=$(grep -c '' ${file})\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "            ./onmi ./gts/gt_xm_s${i}_co.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check path results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(path_method):\n",
    "    current_dir = os.getcwd()\n",
    "    print(current_dir)\n",
    "    method_name = path_method.split(\"\\\\\")[1]\n",
    "#     print(method_name)\n",
    "    res = os.path.exists(path_method)\n",
    "    # clean the folder to save new data\n",
    "    if res:\n",
    "        #check if it is empty\n",
    "        dir_empty = os.listdir(path_method)\n",
    "        if len(dir_empty) != 0:\n",
    "    #         shutil.rmtree(\"OutputAnalysis/kmeans/\")\n",
    "            rm = !rm -r --preserve-root './OutputAnalysis/'{method_name}'/'*\n",
    "            if not rm:\n",
    "                print(method_name+\"' folder was cleaned.\")\n",
    "    #             os.chdir(path_method)\n",
    "            else:\n",
    "                print(\"sad\")\n",
    "                print(rm)\n",
    "        else:\n",
    "            print(\"This folder is Empty!\")\n",
    "            pass\n",
    "    #         os.chdir(path_method)\n",
    "    else: # nothing exist so create it\n",
    "        # trying to insert to flase directory \n",
    "        try: \n",
    "    #         os.chdir(fd) \n",
    "            os.mkdir(path_method)\n",
    "            print(\"The path was created: \"+path_method)\n",
    "\n",
    "        # Caching the exception     \n",
    "        except: \n",
    "            print(\"Something wrong with specified directory. Exception- \", sys.exc_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format result to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clustering_output_omega(clusters,clus_labels,trad=False):\n",
    "    # build the clustering output format to use in the omega index evaluation\n",
    "    clustering = {}\n",
    "    num_of_elements = 0\n",
    "    \n",
    "    if trad:\n",
    "        for cluster_id in clusters:\n",
    "            clustering[\"c\"+str(cluster_id)] = []\n",
    "            for index, value in enumerate(clus_labels[0]):#looping over the labels\n",
    "                if cluster_id == value:\n",
    "                    [clustering[\"c\"+str(cluster_id)].append((\"01\"+str(index)+\"02\"+str(j))) for j in range(clus_labels[1])]# num of attributes\n",
    "            num_of_elements+=len(clustering[\"c\"+str(cluster_id)])\n",
    "    else:\n",
    "        if isinstance(clusters,int):\n",
    "            num = clusters\n",
    "        else:\n",
    "            num = (clusters[0]*clusters[1])\n",
    "\n",
    "        seq_index = 0\n",
    "        for nc in range(num):\n",
    "             ## check if exist some co-cluster with no element assignment for object and attribute\n",
    "#             if len(clus_labels.get_indices(nc)[0]) != 0 and len(clus_labels.get_indices(nc)[1]) != 0:\n",
    "#                 clustering[\"c\"+str(seq_index)] = []\n",
    "#                 for i in clus_labels.get_indices(nc)[0]:\n",
    "#                     for j in clus_labels.get_indices(nc)[1]:\n",
    "#                         clustering[\"c\"+str(seq_index)].append((\"01\"+str(i)+\"02\"+str(j)))\n",
    "#             elif len(clus_labels.get_indices(nc)[0]) != 0 and len(clus_labels.get_indices(nc)[1]) == 0:\n",
    "#                 clustering[\"c\"+str(seq_index)] = []\n",
    "#                 for i in clus_labels.get_indices(nc)[0]:\n",
    "#                     clustering[\"c\"+str(seq_index)].append(str(i))\n",
    "#             elif len(clus_labels.get_indices(nc)[1]) != 0 and len(clus_labels.get_indices(nc)[0]) == 0:\n",
    "#                 clustering[\"c\"+str(seq_index)] = []\n",
    "#                 for j in clus_labels.get_indices(nc)[1]:\n",
    "#                     clustering[\"c\"+str(seq_index)].append(str(j))\n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "#             num_of_elements += len(clustering[\"c\"+str(seq_index)])\n",
    "#             seq_index += 1\n",
    "            \n",
    "            \n",
    "            ## check if exist some co-cluster with no element assignment for object and attribute\n",
    "            if len(clus_labels.get_indices(nc)[0]) != 0 and len(clus_labels.get_indices(nc)[1]) != 0:\n",
    "                clustering[\"c\"+str(seq_index)] = []\n",
    "                for i in clus_labels.get_indices(nc)[0]:\n",
    "                    for j in clus_labels.get_indices(nc)[1]:\n",
    "                        clustering[\"c\"+str(seq_index)].append((\"01\"+str(i)+\"02\"+str(j)))\n",
    "                num_of_elements += len(clustering[\"c\"+str(seq_index)])\n",
    "                seq_index+=1\n",
    "#         print(\"Number of elements in OMEGA format: \",num_of_elements)\n",
    "    return clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xmeasures_format(dict_gt):\n",
    "    newData = []\n",
    "#     print(len(dict_gt))\n",
    "    r = 0\n",
    "    for i in range(len(dict_gt)):\n",
    "#         print(i,end=\":\")\n",
    "        stringLine = str(dict_gt['c'+str(i)][0])\n",
    "#         print(len(dict_gt['c'+str(i)]),end=\",\")\n",
    "        r += len(dict_gt['c'+str(i)])\n",
    "        for j in range(1,len(dict_gt['c'+str(i)])):\n",
    "#             stringLine = stringLine+\" \"+dict_gt['c'+str(i)][j]\n",
    "            stringLine += \" \"+str(dict_gt['c'+str(i)][j])\n",
    "        newData.append(stringLine)\n",
    "#     print(\"Number of elements in XMEASURES format: \",r)\n",
    "    return newData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
